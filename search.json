[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fastkg",
    "section": "",
    "text": "This library provides optimized storage solutions for RDFLib graphs, focusing on:",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "fastkg",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall {{lib_path}} in Development mode\n# make sure {{lib_path}} package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to {{lib_path}}\n$ nbdev_prepare",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "fastkg",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/la3d/fastkg.git",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "fastkg",
    "section": "Quick Start",
    "text": "Quick Start\n\nUsing parquet as a fast store\n\nfrom fastkg.core import KnowledgeGraph\nimport rdflib\n\n# Create a knowledge graph\nkg = KnowledgeGraph()\n\n# Add some triples\nex = rdflib.Namespace(\"http://example.org/\")\nkg.bind_ns(\"ex\", ex)\nkg.add((ex.John, rdflib.RDF.type, ex.Person))\nkg.add((ex.John, ex.name, rdflib.Literal(\"John Doe\")))\nkg.add((ex.John, ex.knows, ex.Jane))\n\nprint(f\"Created graph with {len(kg)} triples\")\n\n# Save to Parquet file\nkg.save_parquet(\"example.parquet\")\nprint(\"Saved graph to Parquet file\")\n\n# Load from Parquet file\nkg2 = KnowledgeGraph().load_parquet(\"example.parquet\")\nprint(f\"Loaded {len(kg2)} triples from Parquet file\")\n\n# Query the graph\nresults = list(kg2.query(\"\"\"\n    SELECT ?name WHERE {\n        ?person a &lt;http://example.org/Person&gt; .\n        ?person &lt;http://example.org/name&gt; ?name .\n    }\n\"\"\"))\n\nfor row in results:\n    print(f\"Found person: {row[0]}\")\n\nCreated graph with 3 triples\nSaved graph to Parquet file\nLoaded 3 triples from Parquet file\nFound person: \"John Doe\"\n\n\n\n\nUsing SQLite as a simple triple store.\n\nfrom fastkg.core import KnowledgeGraph\nfrom fastkg.sqlite import *\nimport rdflib\n\n# Create a knowledge graph and connect to SQLite\nkg = KnowledgeGraph()\nkg.connect_sqlite(\"example.db\", create=True)\n\n# Add some triples directly to the SQLite-backed graph\nex = rdflib.Namespace(\"http://example.org/\")\nkg.bind_ns(\"ex\", ex)\nkg.add((ex.John, rdflib.RDF.type, ex.Person))\nkg.add((ex.John, ex.name, rdflib.Literal(\"John Doe\")))\nkg.add((ex.John, ex.knows, ex.Jane))\n\nprint(f\"Added {len(kg)} triples to the database\")\n\n# Close the connection when done\nkg.close();\n\n# Load from SQLite\nkg2 = KnowledgeGraph()\nkg2.connect_sqlite(\"example.db\", create=False)\n\nprint(f\"Loaded {len(kg2)} triples from the database\")\n\n# Query the graph\nresults = list(kg2.query(\"\"\"\n    SELECT ?name WHERE {\n        ?person a &lt;http://example.org/Person&gt; .\n        ?person &lt;http://example.org/name&gt; ?name .\n    }\n\"\"\"))\n\nfor row in results:\n    print(f\"Found person: {row[0]}\")\n\n# Don't forget to close the connection\nkg2.close();\n\nAdded 3 triples to the database\nLoaded 3 triples from the database\nFound person: John Doe",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "index.html#use-cases-for-rag-systems",
    "href": "index.html#use-cases-for-rag-systems",
    "title": "fastkg",
    "section": "Use Cases for RAG Systems",
    "text": "Use Cases for RAG Systems\nThis library is particularly useful for LLM-based Retrieval Augmented Generation systems:\n\nAgent Memory: Store structured knowledge that persists between sessions\nKnowledge Graphs: Maintain entity relationships for complex reasoning\nEfficient Retrieval: Query relevant subgraphs to include in LLM context windows",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "index.html#core-features",
    "href": "index.html#core-features",
    "title": "fastkg",
    "section": "Core Features",
    "text": "Core Features\nThe library includes:\n\nKnowledgeGraph class - A wrapper around RDFLib’s Graph with additional storage capabilities\nParquet storage - Fast columnar storage for large graphs\nSQLite storage - Indexed, portable database storage\nHelper methods for common graph operations",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "fastkg",
    "section": "Contributing",
    "text": "Contributing\nContributions are welcome! Please feel free to submit a Pull Request.\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on [conda][conda] and [pypi][pypi] respectively.",
    "crumbs": [
      "fastkg"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "This module provides a fast, efficient way to store and retrieve RDF graphs using Parquet files. It wraps RDFLib’s graph functionality with optimized Parquet serialization methods.\n\n\n\nSave RDF graphs to compressed Parquet files\nLoad graphs from Parquet with optimized performance\nPreserve all RDF semantics (URIs, blank nodes, literals with datatypes)\nMemory-efficient batch processing for large graphs\nFluent API for method chaining\nSimple integration with existing RDFLib code\n\n\n\n\n\nStore large knowledge graphs efficiently\nImprove load/save times for RDF data\nIntegrate semantic web data with data science pipelines\nReduce storage requirements for RDF datasets\nEnable faster querying through columnar storage benefits\n\nThis module bridges the gap between semantic web technologies and modern data engineering practices, allowing RDF data to benefit from Parquet’s columnar storage format advantages including compression, schema enforcement, and performance.\nThis is inspired by KGLabs implimentation Performance analysis of serialization methods¶ that showed parquet to be a reasonable triple store for local graphs. This also provides some convenience functions for constructing KGs.\n\nsource\n\n\n\n KnowledgeGraph (g=None)\n\nRDFLib wrapper with Parquet storage capabilities\n\nsource\n\n\n\n\n KnowledgeGraph.add (triple)\n\nAdd a triple to the graph\n\nsource\n\n\n\n\n KnowledgeGraph.remove (triple)\n\nRemove a triple from the graph\n\nsource\n\n\n\n\n KnowledgeGraph.bind_ns (prefix, namespace)\n\nBind a namespace prefix\n\nsource\n\n\n\n\n KnowledgeGraph.bind_namespaces (ns_dict)\n\nBind multiple namespace prefixes\n\nsource\n\n\n\n\n KnowledgeGraph.query (q)\n\nRun a SPARQL query\n\nsource\n\n\n\n\n KnowledgeGraph.triples (pattern=None)\n\nReturn triples matching the pattern\n\nsource\n\n\n\n\n KnowledgeGraph.summary ()\n\nPrint a summary of the graph\n\nsource\n\n\n\n\n KnowledgeGraph.to_file (path, format=None)\n\nSave graph to a file in any RDFLib-supported format\n\nsource\n\n\n\n\n KnowledgeGraph.from_file (path, format=None)\n\nLoad graph from a file in any RDFLib-supported format\n\nsource\n\n\n\n\n KnowledgeGraph.__getitem__ (pattern)\n\nGet triples matching a pattern using [] syntax",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#key-features",
    "href": "core.html#key-features",
    "title": "core",
    "section": "",
    "text": "Save RDF graphs to compressed Parquet files\nLoad graphs from Parquet with optimized performance\nPreserve all RDF semantics (URIs, blank nodes, literals with datatypes)\nMemory-efficient batch processing for large graphs\nFluent API for method chaining\nSimple integration with existing RDFLib code",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#use-cases",
    "href": "core.html#use-cases",
    "title": "core",
    "section": "",
    "text": "Store large knowledge graphs efficiently\nImprove load/save times for RDF data\nIntegrate semantic web data with data science pipelines\nReduce storage requirements for RDF datasets\nEnable faster querying through columnar storage benefits\n\nThis module bridges the gap between semantic web technologies and modern data engineering practices, allowing RDF data to benefit from Parquet’s columnar storage format advantages including compression, schema enforcement, and performance.\nThis is inspired by KGLabs implimentation Performance analysis of serialization methods¶ that showed parquet to be a reasonable triple store for local graphs. This also provides some convenience functions for constructing KGs.\n\nsource\n\n\n\n KnowledgeGraph (g=None)\n\nRDFLib wrapper with Parquet storage capabilities\n\nsource\n\n\n\n\n KnowledgeGraph.add (triple)\n\nAdd a triple to the graph\n\nsource\n\n\n\n\n KnowledgeGraph.remove (triple)\n\nRemove a triple from the graph\n\nsource\n\n\n\n\n KnowledgeGraph.bind_ns (prefix, namespace)\n\nBind a namespace prefix\n\nsource\n\n\n\n\n KnowledgeGraph.bind_namespaces (ns_dict)\n\nBind multiple namespace prefixes\n\nsource\n\n\n\n\n KnowledgeGraph.query (q)\n\nRun a SPARQL query\n\nsource\n\n\n\n\n KnowledgeGraph.triples (pattern=None)\n\nReturn triples matching the pattern\n\nsource\n\n\n\n\n KnowledgeGraph.summary ()\n\nPrint a summary of the graph\n\nsource\n\n\n\n\n KnowledgeGraph.to_file (path, format=None)\n\nSave graph to a file in any RDFLib-supported format\n\nsource\n\n\n\n\n KnowledgeGraph.from_file (path, format=None)\n\nLoad graph from a file in any RDFLib-supported format\n\nsource\n\n\n\n\n KnowledgeGraph.__getitem__ (pattern)\n\nGet triples matching a pattern using [] syntax",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "sqlite.html",
    "href": "sqlite.html",
    "title": "sqlite",
    "section": "",
    "text": "This module provides a fast, efficient way to store and retrieve RDF graphs using Parquet files. It wraps RDFLib’s graph functionality with optimized Parquet serialization methods.\n\n\n\nSave RDF graphs to compressed Parquet files\nLoad graphs from Parquet with optimized performance\nPreserve all RDF semantics (URIs, blank nodes, literals with datatypes)\nMemory-efficient batch processing for large graphs\nFluent API for method chaining\nSimple integration with existing RDFLib code\n\n\n\n\n\nStore large knowledge graphs efficiently\nImprove load/save times for RDF data\nIntegrate semantic web data with data science pipelines\nReduce storage requirements for RDF datasets\nEnable faster querying through columnar storage benefits\n\nThis module bridges the gap between semantic web technologies and modern data engineering practices, allowing RDF data to benefit from Parquet’s columnar storage format advantages including compression, schema enforcement, and performance.\nThis is inspired by KGLabs implimentation Performance analysis of serialization methods¶ that showed parquet to be a reasonable triple store for local graphs. This also provides some convenience functions for constructing KGs.\n\nsource\n\n\n\n SQLiteStore (configuration=None)\n\nSimple SQLite-based triple store for RDFLib\n\nsource\n\n\n\n\n KnowledgeGraph.connect_sqlite (db_path, create=True)\n\nConnect to a SQLite database file\n\nsource\n\n\n\n\n KnowledgeGraph.close ()\n\nClose the database connection if using a persistent store\n\n# Step 1: Test basic functionality\ndb_path = \"test_sqlite_store.db\"\nremove_test_db(db_path)  # Clean up any existing test database\n\n# Create a new store\nstore = SQLiteStore()\n\n# Open the store\nresult = store.open(db_path, create=True)\nprint(f\"Open result: {result}\")\n\n# Add a triple\ntest_triple = (\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    Literal(\"test object\")\n)\nstore.add(test_triple)\n\n# Check if the triple was added\nprint(f\"Store length: {len(store)}\")\n\n# Query for the triple\nresults = list(store.triples((None, None, None)))\nprint(f\"All triples: {results}\")\n\n# Close the store\nstore.close()\n\nOpen result: 1\nStore length: 1\nAll triples: [((rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object')), None)]\n\n\n\n# Step 2: Test query patterns\nstore = SQLiteStore()\nstore.open(db_path)\n\n# Add more triples for testing queries\nstore.add((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/another-predicate\"),\n    Literal(\"another object\")\n))\n\nstore.add((\n    URIRef(\"http://example.org/another-subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    Literal(\"third object\")\n))\n\n# Query with subject pattern\nprint(\"Query with subject pattern:\")\nresults = list(store.triples((URIRef(\"http://example.org/subject\"), None, None)))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\n# Query with predicate pattern\nprint(\"\\nQuery with predicate pattern:\")\nresults = list(store.triples((None, URIRef(\"http://example.org/predicate\"), None)))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\n# Query with object pattern\nprint(\"\\nQuery with object pattern:\")\nresults = list(store.triples((None, None, Literal(\"test object\"))))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\n# Query with subject-predicate pattern\nprint(\"\\nQuery with subject-predicate pattern:\")\nresults = list(store.triples((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    None\n)))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\nstore.close()\n\nQuery with subject pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/another-predicate'), rdflib.term.Literal('another object'))\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n\nQuery with predicate pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n  (rdflib.term.URIRef('http://example.org/another-subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('third object'))\n\nQuery with object pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n\nQuery with subject-predicate pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n\n\n\n# Step 3: Test different RDF term types\nstore = SQLiteStore()\nstore.open(db_path)\n\n# Add triples with different term types\n# Blank node\nbnode = BNode()\nstore.add((bnode, URIRef(\"http://example.org/type\"), Literal(\"blank node\")))\n\n# Literal with language tag\nstore.add((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/label\"),\n    Literal(\"hello\", lang=\"en\")\n))\n\n# Literal with datatype\nstore.add((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/age\"),\n    Literal(\"42\", datatype=URIRef(\"http://www.w3.org/2001/XMLSchema#integer\"))\n))\n\n# Query for specific term types\nprint(\"Blank node triples:\")\nfor triple, ctx in store.triples((None, URIRef(\"http://example.org/type\"), None)):\n    print(f\"  {triple}\")\n    print(f\"  Subject type: {type(triple[0])}\")\n\nprint(\"\\nLanguage-tagged literal:\")\nfor triple, ctx in store.triples((None, URIRef(\"http://example.org/label\"), None)):\n    print(f\"  {triple}\")\n    print(f\"  Object language: {triple[2].language}\")\n\nprint(\"\\nDatatyped literal:\")\nfor triple, ctx in store.triples((None, URIRef(\"http://example.org/age\"), None)):\n    print(f\"  {triple}\")\n    print(f\"  Object datatype: {triple[2].datatype}\")\n\nstore.close()\n\nBlank node triples:\n  (rdflib.term.BNode('Nc109a8aa596b4894b86367280c0726cc'), rdflib.term.URIRef('http://example.org/type'), rdflib.term.Literal('blank node'))\n  Subject type: &lt;class 'rdflib.term.BNode'&gt;\n\nLanguage-tagged literal:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/label'), rdflib.term.Literal('hello', lang='en'))\n  Object language: en\n\nDatatyped literal:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/age'), rdflib.term.Literal('42', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#integer')))\n  Object datatype: http://www.w3.org/2001/XMLSchema#integer\n\n\n\n# Step 4: Test removal\nstore = SQLiteStore()\nstore.open(db_path)\n\n# Count triples before removal\nprint(f\"Triples before removal: {len(store)}\")\n\n# Remove a specific triple\nstore.remove((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    Literal(\"test object\")\n))\n\nprint(f\"Triples after specific removal: {len(store)}\")\n\n# Remove triples matching a pattern\nstore.remove((URIRef(\"http://example.org/subject\"), None, None))\n\nprint(f\"Triples after pattern removal: {len(store)}\")\n\n# Check remaining triples\nprint(\"Remaining triples:\")\nfor triple, ctx in store.triples((None, None, None)):\n    print(f\"  {triple}\")\n\nstore.close()\n\nTriples before removal: 6\nTriples after specific removal: 5\nTriples after pattern removal: 2\nRemaining triples:\n  (rdflib.term.URIRef('http://example.org/another-subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('third object'))\n  (rdflib.term.BNode('Nc109a8aa596b4894b86367280c0726cc'), rdflib.term.URIRef('http://example.org/type'), rdflib.term.Literal('blank node'))\n\n\n\n# Test with KnowledgeGraph\nkg_db_path = \"test_kg_sqlite.db\"\nremove_test_db(kg_db_path)  # Clean up any existing test database\n\n# Create a new graph\nkg = KnowledgeGraph()\nkg.connect_sqlite(kg_db_path)\n\n# Add some data\nex = rdflib.Namespace(\"http://example.org/\")\nkg.bind_ns(\"ex\", ex)\nkg.add((ex.John, rdflib.RDF.type, ex.Person))\nkg.add((ex.John, ex.name, rdflib.Literal(\"John Doe\")))\nkg.add((ex.John, ex.age, rdflib.Literal(30)))\n\nprint(f\"Added {len(kg)} triples to SQLite database\")\n\n# Run a SPARQL query\nq = \"\"\"\nSELECT ?name WHERE {\n  ?person a &lt;http://example.org/Person&gt; .\n  ?person &lt;http://example.org/name&gt; ?name .\n}\n\"\"\"\nresults = list(kg.query(q))\nprint(f\"Query result: {results[0][0] if results else 'No results'}\")\n\n# Close the connection\nkg.close()\n\n# Connect to the same DB with a new graph\nkg2 = KnowledgeGraph()\nkg2.connect_sqlite(kg_db_path, create=False)\nprint(f\"Loaded graph has {len(kg2)} triples\")\n\n# Run the same query\nresults = list(kg2.query(q))\nprint(f\"Query result after reload: {results[0][0] if results else 'No results'}\")\n\nkg2.close()\n\nAdded 3 triples to SQLite database\nQuery result: John Doe\nLoaded graph has 3 triples\nQuery result after reload: John Doe\n\n\nKnowledgeGraph(triples=0)",
    "crumbs": [
      "sqlite"
    ]
  },
  {
    "objectID": "sqlite.html#key-features",
    "href": "sqlite.html#key-features",
    "title": "sqlite",
    "section": "",
    "text": "Save RDF graphs to compressed Parquet files\nLoad graphs from Parquet with optimized performance\nPreserve all RDF semantics (URIs, blank nodes, literals with datatypes)\nMemory-efficient batch processing for large graphs\nFluent API for method chaining\nSimple integration with existing RDFLib code",
    "crumbs": [
      "sqlite"
    ]
  },
  {
    "objectID": "sqlite.html#use-cases",
    "href": "sqlite.html#use-cases",
    "title": "sqlite",
    "section": "",
    "text": "Store large knowledge graphs efficiently\nImprove load/save times for RDF data\nIntegrate semantic web data with data science pipelines\nReduce storage requirements for RDF datasets\nEnable faster querying through columnar storage benefits\n\nThis module bridges the gap between semantic web technologies and modern data engineering practices, allowing RDF data to benefit from Parquet’s columnar storage format advantages including compression, schema enforcement, and performance.\nThis is inspired by KGLabs implimentation Performance analysis of serialization methods¶ that showed parquet to be a reasonable triple store for local graphs. This also provides some convenience functions for constructing KGs.\n\nsource\n\n\n\n SQLiteStore (configuration=None)\n\nSimple SQLite-based triple store for RDFLib\n\nsource\n\n\n\n\n KnowledgeGraph.connect_sqlite (db_path, create=True)\n\nConnect to a SQLite database file\n\nsource\n\n\n\n\n KnowledgeGraph.close ()\n\nClose the database connection if using a persistent store\n\n# Step 1: Test basic functionality\ndb_path = \"test_sqlite_store.db\"\nremove_test_db(db_path)  # Clean up any existing test database\n\n# Create a new store\nstore = SQLiteStore()\n\n# Open the store\nresult = store.open(db_path, create=True)\nprint(f\"Open result: {result}\")\n\n# Add a triple\ntest_triple = (\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    Literal(\"test object\")\n)\nstore.add(test_triple)\n\n# Check if the triple was added\nprint(f\"Store length: {len(store)}\")\n\n# Query for the triple\nresults = list(store.triples((None, None, None)))\nprint(f\"All triples: {results}\")\n\n# Close the store\nstore.close()\n\nOpen result: 1\nStore length: 1\nAll triples: [((rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object')), None)]\n\n\n\n# Step 2: Test query patterns\nstore = SQLiteStore()\nstore.open(db_path)\n\n# Add more triples for testing queries\nstore.add((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/another-predicate\"),\n    Literal(\"another object\")\n))\n\nstore.add((\n    URIRef(\"http://example.org/another-subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    Literal(\"third object\")\n))\n\n# Query with subject pattern\nprint(\"Query with subject pattern:\")\nresults = list(store.triples((URIRef(\"http://example.org/subject\"), None, None)))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\n# Query with predicate pattern\nprint(\"\\nQuery with predicate pattern:\")\nresults = list(store.triples((None, URIRef(\"http://example.org/predicate\"), None)))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\n# Query with object pattern\nprint(\"\\nQuery with object pattern:\")\nresults = list(store.triples((None, None, Literal(\"test object\"))))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\n# Query with subject-predicate pattern\nprint(\"\\nQuery with subject-predicate pattern:\")\nresults = list(store.triples((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    None\n)))\nfor triple, ctx in results:\n    print(f\"  {triple}\")\n\nstore.close()\n\nQuery with subject pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/another-predicate'), rdflib.term.Literal('another object'))\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n\nQuery with predicate pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n  (rdflib.term.URIRef('http://example.org/another-subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('third object'))\n\nQuery with object pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n\nQuery with subject-predicate pattern:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('test object'))\n\n\n\n# Step 3: Test different RDF term types\nstore = SQLiteStore()\nstore.open(db_path)\n\n# Add triples with different term types\n# Blank node\nbnode = BNode()\nstore.add((bnode, URIRef(\"http://example.org/type\"), Literal(\"blank node\")))\n\n# Literal with language tag\nstore.add((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/label\"),\n    Literal(\"hello\", lang=\"en\")\n))\n\n# Literal with datatype\nstore.add((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/age\"),\n    Literal(\"42\", datatype=URIRef(\"http://www.w3.org/2001/XMLSchema#integer\"))\n))\n\n# Query for specific term types\nprint(\"Blank node triples:\")\nfor triple, ctx in store.triples((None, URIRef(\"http://example.org/type\"), None)):\n    print(f\"  {triple}\")\n    print(f\"  Subject type: {type(triple[0])}\")\n\nprint(\"\\nLanguage-tagged literal:\")\nfor triple, ctx in store.triples((None, URIRef(\"http://example.org/label\"), None)):\n    print(f\"  {triple}\")\n    print(f\"  Object language: {triple[2].language}\")\n\nprint(\"\\nDatatyped literal:\")\nfor triple, ctx in store.triples((None, URIRef(\"http://example.org/age\"), None)):\n    print(f\"  {triple}\")\n    print(f\"  Object datatype: {triple[2].datatype}\")\n\nstore.close()\n\nBlank node triples:\n  (rdflib.term.BNode('Nc109a8aa596b4894b86367280c0726cc'), rdflib.term.URIRef('http://example.org/type'), rdflib.term.Literal('blank node'))\n  Subject type: &lt;class 'rdflib.term.BNode'&gt;\n\nLanguage-tagged literal:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/label'), rdflib.term.Literal('hello', lang='en'))\n  Object language: en\n\nDatatyped literal:\n  (rdflib.term.URIRef('http://example.org/subject'), rdflib.term.URIRef('http://example.org/age'), rdflib.term.Literal('42', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#integer')))\n  Object datatype: http://www.w3.org/2001/XMLSchema#integer\n\n\n\n# Step 4: Test removal\nstore = SQLiteStore()\nstore.open(db_path)\n\n# Count triples before removal\nprint(f\"Triples before removal: {len(store)}\")\n\n# Remove a specific triple\nstore.remove((\n    URIRef(\"http://example.org/subject\"),\n    URIRef(\"http://example.org/predicate\"),\n    Literal(\"test object\")\n))\n\nprint(f\"Triples after specific removal: {len(store)}\")\n\n# Remove triples matching a pattern\nstore.remove((URIRef(\"http://example.org/subject\"), None, None))\n\nprint(f\"Triples after pattern removal: {len(store)}\")\n\n# Check remaining triples\nprint(\"Remaining triples:\")\nfor triple, ctx in store.triples((None, None, None)):\n    print(f\"  {triple}\")\n\nstore.close()\n\nTriples before removal: 6\nTriples after specific removal: 5\nTriples after pattern removal: 2\nRemaining triples:\n  (rdflib.term.URIRef('http://example.org/another-subject'), rdflib.term.URIRef('http://example.org/predicate'), rdflib.term.Literal('third object'))\n  (rdflib.term.BNode('Nc109a8aa596b4894b86367280c0726cc'), rdflib.term.URIRef('http://example.org/type'), rdflib.term.Literal('blank node'))\n\n\n\n# Test with KnowledgeGraph\nkg_db_path = \"test_kg_sqlite.db\"\nremove_test_db(kg_db_path)  # Clean up any existing test database\n\n# Create a new graph\nkg = KnowledgeGraph()\nkg.connect_sqlite(kg_db_path)\n\n# Add some data\nex = rdflib.Namespace(\"http://example.org/\")\nkg.bind_ns(\"ex\", ex)\nkg.add((ex.John, rdflib.RDF.type, ex.Person))\nkg.add((ex.John, ex.name, rdflib.Literal(\"John Doe\")))\nkg.add((ex.John, ex.age, rdflib.Literal(30)))\n\nprint(f\"Added {len(kg)} triples to SQLite database\")\n\n# Run a SPARQL query\nq = \"\"\"\nSELECT ?name WHERE {\n  ?person a &lt;http://example.org/Person&gt; .\n  ?person &lt;http://example.org/name&gt; ?name .\n}\n\"\"\"\nresults = list(kg.query(q))\nprint(f\"Query result: {results[0][0] if results else 'No results'}\")\n\n# Close the connection\nkg.close()\n\n# Connect to the same DB with a new graph\nkg2 = KnowledgeGraph()\nkg2.connect_sqlite(kg_db_path, create=False)\nprint(f\"Loaded graph has {len(kg2)} triples\")\n\n# Run the same query\nresults = list(kg2.query(q))\nprint(f\"Query result after reload: {results[0][0] if results else 'No results'}\")\n\nkg2.close()\n\nAdded 3 triples to SQLite database\nQuery result: John Doe\nLoaded graph has 3 triples\nQuery result after reload: John Doe\n\n\nKnowledgeGraph(triples=0)",
    "crumbs": [
      "sqlite"
    ]
  }
]